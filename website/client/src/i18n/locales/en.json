{
  "nav": {
    "title": "Chess LLM Arena",
    "leaderboard": "Leaderboard",
    "analytics": "Analytics",
    "about": "About",
    "toggleTheme": "Toggle Theme",
    "toggleLanguage": "Toggle Language"
  },
  "leaderboard": {
    "title": "Leaderboard",
    "subtitle": "Top performing LLM Chess Agents",
    "activeAgents": "{{count}} Agents Active",
    "table": {
      "rank": "Rank",
      "model": "Model",
      "rating": "Rating",
      "rd": "RD",
      "winRate": "Win Rate",
      "games": "Games"
    }
  },
  "agentDetail": {
    "backToLeaderboard": "Back to Leaderboard",
    "rating": "Rating",
    "gamesPlayed": "Games Played",
    "winRate": "Win Rate",
    "isReasoning": "Reasoning Model",
    "isRandom": "Random Baseline",
    "stats": {
      "volatility": "Volatility",
      "volatilitySubtitle": "Rating stability",
      "evaluationIndex": "Evaluation Index",
      "glickoRating": "Glicko-2 Rating",
      "ratingDeviation": "Rating Deviation (RD)"
    },
    "performanceBreakdown": "Performance Breakdown",
    "gameHistory": "Game History",
    "filters": {
      "allTypes": "All Types",
      "allOutcomes": "All Outcomes",
      "success": "Success",
      "failed": "Failed"
    },
    "table": {
      "puzzle": "Puzzle",
      "type": "Type",
      "outcome": "Outcome",
      "moves": "Moves",
      "date": "Date"
    },
    "pagination": {
      "previous": "Previous Page",
      "next": "Next Page",
      "showing": "Showing {{start}} - {{end}} of {{total}}"
    },
    "statLabel": "Stat"
  },
  "replay": {
    "backToAgent": "Back to Agent",
    "gameDetails": "Game Details",
    "model": "Model",
    "puzzleId": "Puzzle ID",
    "outcome": "Outcome",
    "success": "Success",
    "failed": "Failed",
    "moves": "Moves",
    "viewOnLichess": "View on Lichess",
    "illegalMove": "Illegal Move",
    "hallucination": "Piece Ownership Hallucination",
    "controls": {
      "first": "First Move",
      "prev": "Previous Move",
      "next": "Next Move",
      "last": "Last Move"
    },
    "history": {
      "title": "Move History",
      "white": "White",
      "black": "Black",
      "step": "Step {{step}}",
      "illegalAttempt": "Illegal attempt: {{move}}",
      "reason": "Reason: {{reason}}"
    },
    "messages": {
      "hallucination": "The agent tried to move a non-existent {{piece}} to {{target}} (Hallucination).",
      "illegal": "The agent tried to move {{piece}} to {{target}}, but it was an illegal move.",
      "genericIllegal": "The agent selected an illegal move ({{move}}).",
      "incorrect": "The agent played {{move}}, but the optimal move was {{expected}}.",
      "notationError": "Notation Error",
      "illegalMove": "Illegal Move",
      "incorrectMove": "Incorrect Move"
    },
    "sidebar": {
      "open": "Open Sidebar",
      "close": "Close Sidebar",
      "playingAs": "Playing as:",
      "popularity": "Popularity",
      "type": "Type",
      "plays": "Plays",
      "themes": "Themes",
      "openingTags": "Opening Tags",
      "openOnLichess": "Open",
      "goToMove": "Go to move {{number}} {{color}} {{move}}"
    },
    "tooltips": {
      "puzzleRating": "Puzzle rating (Glicko-2) based on solver performance.",
      "popularity": "Popularity ranges from 100 to -100 and reflects weighted upvotes/downvotes.",
      "puzzleCategory": "Puzzle category from Lichess (e.g., mate, advantage, equality).",
      "lichessPlays": "Number of times this puzzle was played on Lichess.",
      "tacticalMotifs": "Tactical motifs tagged by Lichess (e.g., fork, pin, skewer).",
      "openingTags": "Opening tags are provided when the puzzle starts before move 20.",
      "lichessOpening": "Opening classification tag from Lichess.",
      "puzzleId": "Unique Lichess puzzle identifier.",
      "moveHistoryList": "Chronological move list for this attempt. Click a move to jump to it."
    },
    "puzzleTypes": {
      "mate": "Find a forced sequence leading to checkmate.",
      "advantage": "Exploit a superior position to win material or gain a decisive advantage.",
      "equality": "Find the only move that saves the game and maintains balance in a worse position.",
      "tactic": "Precise sequence to gain an immediate advantage.",
      "strategy": "Long-term plan based on positional considerations (pawn structure, strong squares).",
      "endgame": "Final phase with reduced material. Precision and king activity are crucial.",
      "middlegame": "Complex phase with most pieces. Combines tactical calculation and strategic planning.",
      "opening": "Initial moves of the game. Goals: development, center control, and king safety."
    },
    "themes": {
      "fork": "A single move attacks two or more pieces at once.",
      "pin": "A piece cannot move because it would expose a more valuable piece.",
      "skewer": "Attack a valuable piece so it must move, exposing a lesser piece.",
      "discoveredattack": "Move a piece to reveal an attack from another piece.",
      "doubleattack": "A move that creates two simultaneous threats.",
      "sacrifice": "Give up material for a tactical gain.",
      "attraction": "Lure a piece to a vulnerable square.",
      "deflection": "Force a defender away from a key square or piece.",
      "clearance": "Clear a square or file to enable a tactic.",
      "interference": "Block a line between a piece and its target.",
      "advantage": "Gain a winning or near-winning position.",
      "equality": "Hold or restore a roughly equal position.",
      "tactic": "A short tactical sequence to win material or mate.",
      "strategy": "A longer-term plan to improve position or structure.",
      "backrankmate": "Checkmate along the back rank with blocked escape squares.",
      "smotheredmate": "Checkmate where the king is blocked by its own pieces.",
      "mate": "A forced checkmate motif.",
      "matein1": "Checkmate in one move.",
      "matein2": "Checkmate in two moves.",
      "matein3": "Checkmate in three moves.",
      "perpetualcheck": "Force a draw by repeated checking.",
      "zugzwang": "Any move worsens the position.",
      "endgame": "Final phase with reduced material. Precision and king activity are crucial.",
      "middlegame": "Complex phase with most pieces. Combines tactical calculation and strategic planning.",
      "opening": "Initial moves of the game. Goals: development, center control, and king safety."
    }
  },
  "analytics": {
    "charts": {
      "ratingTrends": {
        "title": "Model Rating Trends",
        "desc": "Glicko-2 rating evolution across evaluation periods"
      },
      "ratingDeviation": {
        "title": "Rating Deviation Trends",
        "desc": "Confidence intervals (RD) decreasing as models solve more puzzles"
      },
      "illegalMoves": {
        "title": "Illegal Move Rate",
        "desc": "Percentage of attempted moves that were invalid according to FIDE rules"
      },
      "puzzleOutcomes": {
        "title": "Overall Puzzle Outcomes",
        "desc": "Success vs failure counts aggregated by puzzle theme"
      },
      "tokenEfficiency": {
        "title": "Token Efficiency",
        "desc": "Average prompt and completion tokens used per move"
      },
      "finalRatings": {
        "title": "Final Rating Confidence Intervals",
        "desc": "95% confidence intervals (±2 RD) compared against the benchmark puzzle difficulty (green band)"
      }
    }
  },
  "about": {
    "header": {
      "title": "Chess LLM Arena",
      "subtitle": "Comparative Analysis of Language Model Performance in Chess",
      "originalTitle": "Original Title: Analyse comparative des performances des modèles de langage dans le jeu d'échecs",
      "readReport": "Read Full Report (French only)"
    },
    "abstract": {
      "title": "Abstract",
      "p1": "This work presents an evaluation of various Large Language Models (LLMs) on chess puzzle solving tasks. We developed an automatic evaluation system that uses the Glicko-2 rating to compare the performance of five models. The evaluation consisted of testing these models on a diverse set of chess puzzles from the Lichess database, distributed across three themes: End Game, Strategic, and Tactic.",
      "p2": "Our results reveal that they all obtained a ranking lower than the average level of approximately 1500. The best performing model (nvidia/llama-3.1-nemotron-ultra-253b-v1) only reached about 705 ± 81 points. We observed that the size and architecture of the model did not systematically correlate with performance.",
      "p3": "This research highlights the current limitations of LLMs in chess reasoning tasks and suggests that neither model size nor Chain-of-Thought training are indicators of performance in complex strategic games."
    },
    "methodology": {
      "title": "Methodology",
      "framework": "Framework: Automated Python evaluation system using Glicko-2 ratings.",
      "dataset": "Dataset: 1,400 puzzles from Lichess (Endgame, Strategic, Tactics).",
      "models": "Models: 5 LLMs tested via Nvidia NIM & OpenRouter APIs.",
      "baselines": "Baselines: Stockfish (~1500 Elo) and Random Agent."
    },
    "findings": {
      "title": "Key Findings",
      "performance": "Sub-Human Performance: Best model reached ~705 Elo (vs 1500 human avg).",
      "size": "Size ≠ Skill: Larger models (405B) did not significantly outperform smaller ones.",
      "hallucinations": "Hallucinations: High rate of illegal moves, especially without Chain-of-Thought.",
      "gap": "Reasoning Gap: LLMs struggle with strict logic and lookahead planning."
    },
    "team": {
      "title": "Research Team",
      "authors": "Authors",
      "supervisor": "Supervisor",
      "institution": "Institution",
      "institutionName": "Université du Québec en Outaouais (UQO)",
      "department": "Département d'informatique et d'ingénierie"
    }
  },
  "common": {
    "error": "Error",
    "retry": "Retry",
    "loading": "Loading...",
    "noData": "No data available",
    "appName": "Chess LLM Arena"
  },
  "colors": {
    "white": "White",
    "black": "Black"
  }
}
